{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "0\n",
      "GeForce RTX 3080 Ti\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/liul-storage/gpu-multiagent\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.8/site-packages (7.6.5)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (1.0.2)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (3.5.2)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (6.5.0)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (7.29.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (5.1.3)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.1)\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\n",
      "Requirement already satisfied: jupyter-client<8.0 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (7.0.6)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (5.1.0)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (0.18.0)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (2.10.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (3.0.22)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (58.5.3)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.8/site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.2)\n",
      "Requirement already satisfied: pyzmq>=13 in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (22.3.0)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (1.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (0.3)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (4.9.1)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/conda/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets) (4.2.1)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (0.18.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (21.2.0)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (5.4.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /opt/conda/lib/python3.8/site-packages (from importlib-resources>=1.4.0->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (3.6.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.8/site-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.1->jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (1.15.0)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /opt/conda/lib/python3.8/site-packages (from widgetsnbextension~=3.5.0->ipywidgets) (6.4.1)\n",
      "Requirement already satisfied: argon2-cffi in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (21.1.0)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.8.0)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.0.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.12.1)\n",
      "Requirement already satisfied: nbconvert in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (6.2.0)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.12.0)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.8/site-packages (from cffi>=1.0.0->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.20)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.8/site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: testpath in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.0)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (4.1.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.7.1)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.6)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.8/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (21.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.0.5)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from tensorforce import Agent, Environment, Runner\n",
    "\n",
    "\n",
    "class MultiactorEnvironment(Environment):\n",
    "    \"\"\"\n",
    "    Example multi-actor environment, illustrating best-practice implementation pattern.\n",
    "    State space: position in [0, 10].\n",
    "    Action space: movement in {-1, 0, 1}.\n",
    "    Random start in [3, 7].\n",
    "    Actor 1 perspective as is, actor 2 perspective mirrored.\n",
    "    Positive reward for being closer to 10.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def states(self):\n",
    "        return dict(type='int', num_values=11)\n",
    "\n",
    "    def actions(self):\n",
    "        return dict(type='int', num_values=3)\n",
    "\n",
    "    def num_actors(self):\n",
    "        return 2  # Indicates that environment has multiple actors\n",
    "\n",
    "    def reset(self):\n",
    "        # Always for multi-actor environments: initialize parallel indices\n",
    "        self._parallel_indices = np.arange(self.num_actors())\n",
    "\n",
    "        # Single shared environment logic, plus per-actor perspective\n",
    "        self._states = 3 + np.random.randint(5)\n",
    "        self.second_actor = True\n",
    "        states = np.stack([self._states, 10 - self._states], axis=0)\n",
    "\n",
    "        # Always for multi-actor environments: return per-actor values\n",
    "        return self._parallel_indices.copy(), states\n",
    "\n",
    "    def execute(self, actions):\n",
    "        # Single shared environment logic, plus per-actor perspective\n",
    "        if self.second_actor:\n",
    "            self.second_actor = self.second_actor and not (np.random.random_sample() < 0.1)\n",
    "            terminal = np.stack([False, not self.second_actor], axis=0)\n",
    "            delta = (actions[0] - 1) - (actions[1] - 1)\n",
    "            self._states = np.clip(self._states + delta, a_min=0, a_max=10)\n",
    "            states = np.stack([self._states, 10 - self._states], axis=0)\n",
    "        else:\n",
    "            terminal = np.stack([False], axis=0)\n",
    "            delta = (actions[0] - 1)\n",
    "            self._states = np.clip(self._states + delta, a_min=0, a_max=10)\n",
    "            states = np.stack([self._states], axis=0)\n",
    "        reward = (states - 5.0) / 5.0\n",
    "\n",
    "        # Always for multi-actor environments: update parallel indices, and return per-actor values\n",
    "        self._parallel_indices = self._parallel_indices[~terminal]\n",
    "        return self._parallel_indices.copy(), states, terminal, reward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nrunner = Runner(\\n    # agent='json/ppo.json',\\n    agent=agent,\\n    environment=MultiactorEnvironment,\\n    # max_episode_timesteps=10\\n)\\n\""
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def main():\n",
    "# Multi-actor runner, automatically if environment.num_actors() > 1\n",
    "\n",
    "environment = Environment.create(\n",
    "    environment=MultiactorEnvironment, max_episode_timesteps=10000\n",
    ")\n",
    "\n",
    "'''\n",
    "agent = Agent.create(\n",
    "    agent='tensorforce',\n",
    "    environment=environment,  # alternatively: states, actions, (max_episode_timesteps)\n",
    "    memory=10000,\n",
    "    update=dict(unit='timesteps', batch_size=64),\n",
    "    optimizer=dict(type='adam', learning_rate=3e-4),\n",
    "    policy=dict(network='auto'),\n",
    "    objective='policy_gradient',\n",
    "    reward_estimation=dict(horizon=20)\n",
    ")\n",
    "'''\n",
    "agent = Agent.create(\n",
    "    agent='ppo',\n",
    "    environment=environment,  # alternatively: states, actions, (max_episode_timesteps)\n",
    "    # memory=10000,\n",
    "    # update=dict(unit='timesteps', batch_size=64),\n",
    "    # optimizer=dict(type='adam', learning_rate=3e-4),\n",
    "    # policy=dict(network='auto'),\n",
    "    # objective='policy_gradient',\n",
    "    # reward_estimation=dict(horizon=20),\n",
    "    network={\"type\": \"auto\", \"rnn\": False},\n",
    "    use_beta_distribution=False,\n",
    "    memory=\"minimum\",\n",
    "    batch_size=12,\n",
    "    update_frequency=1,\n",
    "    learning_rate=0.001813150053725916,\n",
    "    multi_step=5,\n",
    "    subsampling_fraction=0.9131375430837279,\n",
    "    likelihood_ratio_clipping=0.09955676846552193,\n",
    "    discount=0.9985351346308641,\n",
    "    #return_processing=null,\n",
    "    #advantage_processing=null,\n",
    "    predict_terminal_values=False,\n",
    "    #reward_processing=null,\n",
    "    baseline={\"type\": \"auto\", \"rnn\":False},\n",
    "    baseline_optimizer={\"optimizer\": \"adam\", \"learning_rate\": 0.003670157218888348, \"multi_step\":10},\n",
    "    l2_regularization=0.0,\n",
    "    entropy_regularization=0.0011393096635237982,\n",
    "    state_preprocessing=\"linear_normalization\",\n",
    "    exploration=0.0,\n",
    "    variable_noise=0.0\n",
    ")\n",
    "\n",
    "'''\n",
    "runner = Runner(\n",
    "    # agent='json/ppo.json',\n",
    "    agent=agent,\n",
    "    environment=MultiactorEnvironment,\n",
    "    # max_episode_timesteps=10\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorSpec(type=int, shape=(), num_values=1)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.parallel_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states = environment.reset()\n",
    "states[1][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_506/2919750722.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menvironment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorforce/agents/agent.py\u001b[0m in \u001b[0;36mact\u001b[0;34m(self, states, internals, parallel, independent, deterministic, evaluation)\u001b[0m\n\u001b[1;32m    413\u001b[0m             )\n\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m         return super().act(\n\u001b[0m\u001b[1;32m    416\u001b[0m             \u001b[0mstates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minternals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minternals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindependent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindependent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorforce/agents/recorder.py\u001b[0m in \u001b[0;36mact\u001b[0;34m(self, states, internals, parallel, independent, deterministic, **kwargs)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0;31m# Check number of inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnum_parallel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m                 raise TensorforceError.value(\n\u001b[1;32m    240\u001b[0m                     \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Agent.act'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margument\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'len(parallel)'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "states = environment.reset()\n",
    "actions = agent.act(states=states[1], parallel=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_506/1645762014.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mterminal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;31m# Episode timestep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menvironment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobserve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterminal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mterminal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorforce/agents/agent.py\u001b[0m in \u001b[0;36mact\u001b[0;34m(self, states, internals, parallel, independent, deterministic, evaluation)\u001b[0m\n\u001b[1;32m    413\u001b[0m             )\n\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m         return super().act(\n\u001b[0m\u001b[1;32m    416\u001b[0m             \u001b[0mstates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minternals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minternals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindependent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindependent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorforce/agents/recorder.py\u001b[0m in \u001b[0;36mact\u001b[0;34m(self, states, internals, parallel, independent, deterministic, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;31m# Process states input and infer batching structure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         states, batched, num_parallel, is_iter_of_dicts = self._process_states_input(\n\u001b[0m\u001b[1;32m    176\u001b[0m             \u001b[0mstates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Agent.act'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         )\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorforce/agents/recorder.py\u001b[0m in \u001b[0;36m_process_states_input\u001b[0;34m(self, states, function_name)\u001b[0m\n\u001b[1;32m    504\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;31m# Single state is batched, iter[state]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m                 \u001b[0;32massert\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstates_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    507\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m                 \u001b[0mnum_instances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for _ in range(2):\n",
    "    # Initialize episode\n",
    "    states = environment.reset()\n",
    "    terminal = False\n",
    "    while not terminal:\n",
    "        # Episode timestep\n",
    "        actions = agent.act(states=states)\n",
    "        states, terminal, reward = environment.execute(actions=actions)\n",
    "        agent.observe(terminal=terminal, reward=reward)\n",
    "        print(states)\n",
    "        print(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_506/2576467638.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorforce/agents/agent.py\u001b[0m in \u001b[0;36mact\u001b[0;34m(self, states, internals, parallel, independent, deterministic, evaluation)\u001b[0m\n\u001b[1;32m    413\u001b[0m             )\n\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m         return super().act(\n\u001b[0m\u001b[1;32m    416\u001b[0m             \u001b[0mstates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minternals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minternals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindependent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindependent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorforce/agents/recorder.py\u001b[0m in \u001b[0;36mact\u001b[0;34m(self, states, internals, parallel, independent, deterministic, **kwargs)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0;31m# Check number of inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnum_parallel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m                 raise TensorforceError.value(\n\u001b[1;32m    240\u001b[0m                     \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Agent.act'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margument\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'len(parallel)'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88e46074c911430e888ff79017be941e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Episodes:   0%|          | 0/1000 [00:00, return=0.00, ts/ep=0, sec/ep=0.00, ms/ts=0.0, agent=0.0%]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"baseline_optimizer/PartitionedCall:2\", shape=(None,), dtype=int32), values=Tensor(\"baseline_optimizer/PartitionedCall:1\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"baseline_optimizer/PartitionedCall:3\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"policy_optimizer/PartitionedCall:2\", shape=(None,), dtype=int32), values=Tensor(\"policy_optimizer/PartitionedCall:1\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"policy_optimizer/PartitionedCall:3\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "runner.run(num_episodes=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'actions',\n",
       " 'agent',\n",
       " 'batch_agent_calls',\n",
       " 'callback',\n",
       " 'callback_episode_frequency',\n",
       " 'callback_timestep_frequency',\n",
       " 'close',\n",
       " 'environments',\n",
       " 'episode_agent_second',\n",
       " 'episode_agent_seconds',\n",
       " 'episode_return',\n",
       " 'episode_returns',\n",
       " 'episode_seconds',\n",
       " 'episode_start',\n",
       " 'episode_timestep',\n",
       " 'episode_timesteps',\n",
       " 'episodes',\n",
       " 'evaluation',\n",
       " 'evaluation_agent_second',\n",
       " 'evaluation_agent_seconds',\n",
       " 'evaluation_callback',\n",
       " 'evaluation_returns',\n",
       " 'evaluation_run',\n",
       " 'evaluation_seconds',\n",
       " 'evaluation_start',\n",
       " 'evaluation_timesteps',\n",
       " 'handle_act',\n",
       " 'handle_act_evaluation',\n",
       " 'handle_act_joint',\n",
       " 'handle_observe',\n",
       " 'handle_observe_evaluation',\n",
       " 'handle_observe_joint',\n",
       " 'handle_terminal',\n",
       " 'handle_terminal_evaluation',\n",
       " 'is_agent_external',\n",
       " 'is_environment_external',\n",
       " 'is_environment_remote',\n",
       " 'num_environments',\n",
       " 'num_episodes',\n",
       " 'num_sleep_secs',\n",
       " 'num_timesteps',\n",
       " 'num_updates',\n",
       " 'num_vectorized',\n",
       " 'prev_terminals',\n",
       " 'rewards',\n",
       " 'run',\n",
       " 'save_best_agent',\n",
       " 'states',\n",
       " 'sync_episodes',\n",
       " 'sync_timesteps',\n",
       " 'terminals',\n",
       " 'terminate',\n",
       " 'timesteps',\n",
       " 'tqdm',\n",
       " 'tqdm_last_update',\n",
       " 'updates']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(runner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.001223921775818,\n",
       " 2.0195528268814087,\n",
       " 0.008112788200378418,\n",
       " 0.01914513111114502,\n",
       " 0.013635396957397461,\n",
       " 0.013635396957397461,\n",
       " 0.008235573768615723,\n",
       " 0.01928102970123291,\n",
       " 0.010624885559082031,\n",
       " 0.01901841163635254,\n",
       " 0.00402224063873291,\n",
       " 0.023464560508728027,\n",
       " 0.0068738460540771484,\n",
       " 0.020610332489013672,\n",
       " 0.013749241828918457,\n",
       " 0.013749241828918457,\n",
       " 0.013769984245300293,\n",
       " 0.013769984245300293,\n",
       " 0.013679742813110352,\n",
       " 0.013679742813110352,\n",
       " 0.005470156669616699,\n",
       " 0.02170121669769287,\n",
       " 0.006799459457397461,\n",
       " 0.020642757415771484,\n",
       " 0.013522624969482422,\n",
       " 0.013522624969482422,\n",
       " 0.007580280303955078,\n",
       " 0.019850730895996094,\n",
       " 0.004013538360595703,\n",
       " 0.022961854934692383,\n",
       " 0.0040149688720703125,\n",
       " 0.023369312286376953,\n",
       " 0.013428568840026855,\n",
       " 0.013428568840026855,\n",
       " 0.013542532920837402,\n",
       " 0.013542532920837402,\n",
       " 0.013486146926879883,\n",
       " 0.013486146926879883,\n",
       " 0.014803886413574219,\n",
       " 0.014803886413574219,\n",
       " 0.013579368591308594,\n",
       " 0.013579368591308594,\n",
       " 0.013577461242675781,\n",
       " 0.013577461242675781,\n",
       " 0.0040471553802490234,\n",
       " 0.023134708404541016,\n",
       " 0.013863563537597656,\n",
       " 0.013863563537597656,\n",
       " 0.006191253662109375,\n",
       " 0.020928382873535156,\n",
       " 0.013396739959716797,\n",
       " 0.013396739959716797,\n",
       " 0.013559341430664062,\n",
       " 0.013559341430664062,\n",
       " 0.004253029823303223,\n",
       " 0.023371100425720215,\n",
       " 0.003993511199951172,\n",
       " 0.022835969924926758,\n",
       " 0.004637718200683594,\n",
       " 0.02208995819091797,\n",
       " 0.013486027717590332,\n",
       " 0.013486027717590332,\n",
       " 0.013480067253112793,\n",
       " 0.013480067253112793,\n",
       " 0.006084084510803223,\n",
       " 0.02094709873199463,\n",
       " 0.013293862342834473,\n",
       " 0.013293862342834473,\n",
       " 0.013633131980895996,\n",
       " 0.013633131980895996,\n",
       " 0.014064550399780273,\n",
       " 0.014064550399780273,\n",
       " 0.0054798126220703125,\n",
       " 0.021636486053466797,\n",
       " 0.01352548599243164,\n",
       " 0.01352548599243164,\n",
       " 0.0040007829666137695,\n",
       " 0.02285921573638916,\n",
       " 0.004246354103088379,\n",
       " 0.023316502571105957,\n",
       " 0.009443998336791992,\n",
       " 0.01746225357055664,\n",
       " 0.008778929710388184,\n",
       " 0.018131136894226074,\n",
       " 0.013633370399475098,\n",
       " 0.013633370399475098,\n",
       " 0.004219174385070801,\n",
       " 0.02334725856781006,\n",
       " 0.005400300025939941,\n",
       " 0.021353840827941895,\n",
       " 0.003914952278137207,\n",
       " 0.022780776023864746,\n",
       " 0.013379335403442383,\n",
       " 0.013379335403442383,\n",
       " 0.013584733009338379,\n",
       " 0.013584733009338379,\n",
       " 0.006780147552490234,\n",
       " 0.020322561264038086,\n",
       " 0.013381004333496094,\n",
       " 0.013381004333496094,\n",
       " 0.013418316841125488,\n",
       " 0.013418316841125488,\n",
       " 0.006396055221557617,\n",
       " 0.021449804306030273,\n",
       " 0.004689574241638184,\n",
       " 0.022269129753112793,\n",
       " 0.013527393341064453,\n",
       " 0.013527393341064453,\n",
       " 0.013423562049865723,\n",
       " 0.013423562049865723,\n",
       " 0.013741374015808105,\n",
       " 0.013741374015808105,\n",
       " 0.01350867748260498,\n",
       " 0.01350867748260498,\n",
       " 0.005459427833557129,\n",
       " 0.021625161170959473,\n",
       " 0.009499192237854004,\n",
       " 0.017709851264953613,\n",
       " 0.00799250602722168,\n",
       " 0.02022242546081543,\n",
       " 0.0087357759475708,\n",
       " 0.018364310264587402,\n",
       " 0.01343834400177002,\n",
       " 0.01343834400177002,\n",
       " 0.013563156127929688,\n",
       " 0.013563156127929688,\n",
       " 0.004886746406555176,\n",
       " 0.022498011589050293,\n",
       " 0.008171439170837402,\n",
       " 0.01910865306854248,\n",
       " 0.013518810272216797,\n",
       " 0.013518810272216797,\n",
       " 0.013464212417602539,\n",
       " 0.013464212417602539,\n",
       " 0.0069158077239990234,\n",
       " 0.020596981048583984,\n",
       " 0.004063606262207031,\n",
       " 0.023166656494140625,\n",
       " 0.01350867748260498,\n",
       " 0.01350867748260498,\n",
       " 0.008134007453918457,\n",
       " 0.019397377967834473,\n",
       " 0.013672471046447754,\n",
       " 0.013672471046447754,\n",
       " 0.007569789886474609,\n",
       " 0.019989967346191406,\n",
       " 0.006848454475402832,\n",
       " 0.020406365394592285,\n",
       " 0.013477325439453125,\n",
       " 0.013477325439453125,\n",
       " 0.013765335083007812,\n",
       " 0.013765335083007812,\n",
       " 0.005463838577270508,\n",
       " 0.021843671798706055,\n",
       " 0.013598799705505371,\n",
       " 0.013598799705505371,\n",
       " 0.006092548370361328,\n",
       " 0.021505355834960938,\n",
       " 0.01360940933227539,\n",
       " 0.01360940933227539,\n",
       " 0.005474448204040527,\n",
       " 0.021984457969665527,\n",
       " 0.007352113723754883,\n",
       " 0.01945781707763672,\n",
       " 0.013547420501708984,\n",
       " 0.013547420501708984,\n",
       " 0.007697105407714844,\n",
       " 0.01998114585876465,\n",
       " 0.005420327186584473,\n",
       " 0.02178823947906494,\n",
       " 0.01344144344329834,\n",
       " 0.01344144344329834,\n",
       " 0.013410806655883789,\n",
       " 0.013410806655883789,\n",
       " 0.006265163421630859,\n",
       " 0.02123117446899414,\n",
       " 0.007451176643371582,\n",
       " 0.019658923149108887,\n",
       " 0.005404233932495117,\n",
       " 0.02153491973876953,\n",
       " 0.013396024703979492,\n",
       " 0.013396024703979492,\n",
       " 0.0042563676834106445,\n",
       " 0.02414262294769287,\n",
       " 0.01442408561706543,\n",
       " 0.01442408561706543,\n",
       " 0.008702993392944336,\n",
       " 0.020517587661743164,\n",
       " 0.00899660587310791,\n",
       " 0.018799901008605957,\n",
       " 0.013612866401672363,\n",
       " 0.013612866401672363,\n",
       " 0.006859183311462402,\n",
       " 0.020405173301696777,\n",
       " 0.004116177558898926,\n",
       " 0.023201584815979004,\n",
       " 0.007495403289794922,\n",
       " 0.020128250122070312,\n",
       " 0.01367807388305664,\n",
       " 0.01367807388305664,\n",
       " 0.006079673767089844,\n",
       " 0.02101731300354004,\n",
       " 0.01348888874053955,\n",
       " 0.01348888874053955,\n",
       " 0.008800745010375977,\n",
       " 0.018639326095581055,\n",
       " 0.007488727569580078,\n",
       " 0.019621849060058594,\n",
       " 0.013584256172180176,\n",
       " 0.013584256172180176,\n",
       " 0.004018545150756836,\n",
       " 0.02290034294128418,\n",
       " 0.008855342864990234,\n",
       " 0.018706321716308594,\n",
       " 0.008906364440917969,\n",
       " 0.018233299255371094,\n",
       " 0.004725456237792969,\n",
       " 0.02237391471862793,\n",
       " 0.013343095779418945,\n",
       " 0.013343095779418945,\n",
       " 0.009537816047668457,\n",
       " 0.01794898509979248,\n",
       " 0.013561606407165527,\n",
       " 0.013561606407165527,\n",
       " 0.013532876968383789,\n",
       " 0.013532876968383789,\n",
       " 0.0062465667724609375,\n",
       " 0.021214962005615234,\n",
       " 0.006231069564819336,\n",
       " 0.021489620208740234,\n",
       " 0.013558030128479004,\n",
       " 0.013558030128479004,\n",
       " 0.005446314811706543,\n",
       " 0.021674513816833496,\n",
       " 0.0040215253829956055,\n",
       " 0.022873759269714355,\n",
       " 0.007396101951599121,\n",
       " 0.019881844520568848,\n",
       " 0.01349782943725586,\n",
       " 0.01349782943725586,\n",
       " 0.00752103328704834,\n",
       " 0.01983654499053955,\n",
       " 0.01358342170715332,\n",
       " 0.01358342170715332,\n",
       " 0.006124615669250488,\n",
       " 0.021329522132873535,\n",
       " 0.013525843620300293,\n",
       " 0.013525843620300293,\n",
       " 0.007580280303955078,\n",
       " 0.019889116287231445,\n",
       " 0.01346290111541748,\n",
       " 0.01346290111541748,\n",
       " 0.013566851615905762,\n",
       " 0.013566851615905762,\n",
       " 0.005694031715393066,\n",
       " 0.02202427387237549,\n",
       " 0.008176326751708984,\n",
       " 0.01897907257080078,\n",
       " 0.0040471553802490234,\n",
       " 0.023072481155395508,\n",
       " 0.008728504180908203,\n",
       " 0.018813133239746094,\n",
       " 0.009536027908325195,\n",
       " 0.017582178115844727,\n",
       " 0.0074585676193237305,\n",
       " 0.01959836483001709,\n",
       " 0.0068444013595581055,\n",
       " 0.020386099815368652,\n",
       " 0.013394594192504883,\n",
       " 0.013394594192504883,\n",
       " 0.008344650268554688,\n",
       " 0.019210338592529297,\n",
       " 0.008216261863708496,\n",
       " 0.01896512508392334,\n",
       " 0.0074378252029418945,\n",
       " 0.019574522972106934,\n",
       " 0.013548970222473145,\n",
       " 0.013548970222473145,\n",
       " 0.01417994499206543,\n",
       " 0.01417994499206543,\n",
       " 0.004775404930114746,\n",
       " 0.022267460823059082,\n",
       " 0.004662156105041504,\n",
       " 0.022368788719177246,\n",
       " 0.013503670692443848,\n",
       " 0.013503670692443848,\n",
       " 0.005752086639404297,\n",
       " 0.02195596694946289,\n",
       " 0.003991484642028809,\n",
       " 0.023182272911071777,\n",
       " 0.013359546661376953,\n",
       " 0.013359546661376953,\n",
       " 0.0074661970138549805,\n",
       " 0.01996004581451416,\n",
       " 0.009503602981567383,\n",
       " 0.017698049545288086,\n",
       " 0.006814241409301758,\n",
       " 0.020351409912109375,\n",
       " 0.005408287048339844,\n",
       " 0.021531343460083008,\n",
       " 0.008810281753540039,\n",
       " 0.018648624420166016,\n",
       " 0.0055348873138427734,\n",
       " 0.021869421005249023,\n",
       " 0.013518691062927246,\n",
       " 0.013518691062927246,\n",
       " 0.009521245956420898,\n",
       " 0.017655134201049805,\n",
       " 0.013537168502807617,\n",
       " 0.013537168502807617,\n",
       " 0.00983273983001709,\n",
       " 0.018036246299743652,\n",
       " 0.004808902740478516,\n",
       " 0.022591114044189453,\n",
       " 0.013599634170532227,\n",
       " 0.013599634170532227,\n",
       " 0.007528543472290039,\n",
       " 0.020148038864135742,\n",
       " 0.006916403770446777,\n",
       " 0.020518183708190918,\n",
       " 0.00953066349029541,\n",
       " 0.01766812801361084,\n",
       " 0.013417840003967285,\n",
       " 0.013417840003967285,\n",
       " 0.008878350257873535,\n",
       " 0.01857602596282959,\n",
       " 0.00676274299621582,\n",
       " 0.020206928253173828,\n",
       " 0.013390541076660156,\n",
       " 0.013390541076660156,\n",
       " 0.006838798522949219,\n",
       " 0.020198345184326172,\n",
       " 0.008819103240966797,\n",
       " 0.01866602897644043,\n",
       " 0.00683748722076416,\n",
       " 0.02035391330718994,\n",
       " 0.009444236755371094,\n",
       " 0.017650604248046875,\n",
       " 0.004052639007568359,\n",
       " 0.02306199073791504,\n",
       " 0.006730198860168457,\n",
       " 0.020727038383483887,\n",
       " 0.01343083381652832,\n",
       " 0.01343083381652832,\n",
       " 0.008821964263916016,\n",
       " 0.0182650089263916,\n",
       " 0.006828904151916504,\n",
       " 0.02033698558807373,\n",
       " 0.013386011123657227,\n",
       " 0.013386011123657227,\n",
       " 0.004999041557312012,\n",
       " 0.022484421730041504,\n",
       " 0.008715987205505371,\n",
       " 0.018368840217590332,\n",
       " 0.0136491060256958,\n",
       " 0.0136491060256958,\n",
       " 0.004754304885864258,\n",
       " 0.022148847579956055,\n",
       " 0.005161881446838379,\n",
       " 0.023000359535217285,\n",
       " 0.005426168441772461,\n",
       " 0.021606922149658203,\n",
       " 0.013394355773925781,\n",
       " 0.013394355773925781,\n",
       " 0.006121158599853516,\n",
       " 0.021199464797973633,\n",
       " 0.013602018356323242,\n",
       " 0.013602018356323242,\n",
       " 0.007378935813903809,\n",
       " 0.01951920986175537,\n",
       " 0.01339876651763916,\n",
       " 0.01339876651763916,\n",
       " 0.013663291931152344,\n",
       " 0.013663291931152344,\n",
       " 0.01370251178741455,\n",
       " 0.01370251178741455,\n",
       " 0.004767775535583496,\n",
       " 0.02226841449737549,\n",
       " 0.013585090637207031,\n",
       " 0.013585090637207031,\n",
       " 0.008086562156677246,\n",
       " 0.01904284954071045,\n",
       " 0.009995818138122559,\n",
       " 0.019549012184143066,\n",
       " 0.004763484001159668,\n",
       " 0.02225363254547119,\n",
       " 0.005393624305725098,\n",
       " 0.0215378999710083,\n",
       " 0.009429216384887695,\n",
       " 0.017427682876586914,\n",
       " 0.004222750663757324,\n",
       " 0.023249506950378418,\n",
       " 0.013553380966186523,\n",
       " 0.013553380966186523,\n",
       " 0.004578709602355957,\n",
       " 0.022218823432922363,\n",
       " 0.013315439224243164,\n",
       " 0.013315439224243164,\n",
       " 0.01375281810760498,\n",
       " 0.01375281810760498,\n",
       " 0.0075217485427856445,\n",
       " 0.019777655601501465,\n",
       " 0.004012703895568848,\n",
       " 0.023192763328552246,\n",
       " 0.013390660285949707,\n",
       " 0.013390660285949707,\n",
       " 0.005564451217651367,\n",
       " 0.021607637405395508,\n",
       " 0.013463020324707031,\n",
       " 0.013463020324707031,\n",
       " 0.013615131378173828,\n",
       " 0.013615131378173828,\n",
       " 0.013621926307678223,\n",
       " 0.013621926307678223,\n",
       " 0.004328250885009766,\n",
       " 0.023210763931274414,\n",
       " 0.013588786125183105,\n",
       " 0.013588786125183105,\n",
       " 0.006135463714599609,\n",
       " 0.021066665649414062,\n",
       " 0.01361083984375,\n",
       " 0.01361083984375,\n",
       " 0.008452057838439941,\n",
       " 0.01930844783782959,\n",
       " 0.013451814651489258,\n",
       " 0.013451814651489258,\n",
       " 0.006149649620056152,\n",
       " 0.020865321159362793,\n",
       " 0.013508439064025879,\n",
       " 0.013508439064025879,\n",
       " 0.004945635795593262,\n",
       " 0.022739529609680176,\n",
       " 0.004076719284057617,\n",
       " 0.023016929626464844,\n",
       " 0.013436675071716309,\n",
       " 0.013436675071716309,\n",
       " 0.0134199857711792,\n",
       " 0.0134199857711792,\n",
       " 0.004201650619506836,\n",
       " 0.023137331008911133,\n",
       " 0.008719325065612793,\n",
       " 0.018247485160827637,\n",
       " 0.013548135757446289,\n",
       " 0.013548135757446289,\n",
       " 0.013555645942687988,\n",
       " 0.013555645942687988,\n",
       " 0.013998031616210938,\n",
       " 0.013998031616210938,\n",
       " 0.01336359977722168,\n",
       " 0.01336359977722168,\n",
       " 0.013481378555297852,\n",
       " 0.013481378555297852,\n",
       " 0.004047274589538574,\n",
       " 0.023051857948303223,\n",
       " 0.01369166374206543,\n",
       " 0.01369166374206543,\n",
       " 0.013726353645324707,\n",
       " 0.013726353645324707,\n",
       " 0.007596254348754883,\n",
       " 0.019759178161621094,\n",
       " 0.0062046051025390625,\n",
       " 0.02125406265258789,\n",
       " 0.013718724250793457,\n",
       " 0.013718724250793457,\n",
       " 0.006154417991638184,\n",
       " 0.02109968662261963,\n",
       " 0.004802227020263672,\n",
       " 0.02237844467163086,\n",
       " 0.003927707672119141,\n",
       " 0.0230715274810791,\n",
       " 0.013760924339294434,\n",
       " 0.013760924339294434,\n",
       " 0.01348567008972168,\n",
       " 0.01348567008972168,\n",
       " 0.003930449485778809,\n",
       " 0.022736430168151855,\n",
       " 0.01349496841430664,\n",
       " 0.01349496841430664,\n",
       " 0.013688087463378906,\n",
       " 0.013688087463378906,\n",
       " 0.0048149824142456055,\n",
       " 0.022325873374938965,\n",
       " 0.004004240036010742,\n",
       " 0.022986173629760742,\n",
       " 0.004725813865661621,\n",
       " 0.022050976753234863,\n",
       " 0.013611555099487305,\n",
       " 0.013611555099487305,\n",
       " 0.009044408798217773,\n",
       " 0.01860499382019043,\n",
       " 0.013429403305053711,\n",
       " 0.013429403305053711,\n",
       " 0.004699230194091797,\n",
       " 0.022147417068481445,\n",
       " 0.006333112716674805,\n",
       " 0.021427392959594727,\n",
       " 0.008757352828979492,\n",
       " 0.018198251724243164,\n",
       " 0.006111502647399902,\n",
       " 0.02089869976043701,\n",
       " 0.007406949996948242,\n",
       " 0.019571781158447266,\n",
       " 0.009749650955200195,\n",
       " 0.017818927764892578,\n",
       " 0.013478398323059082,\n",
       " 0.013478398323059082,\n",
       " 0.0040596723556518555,\n",
       " 0.022894978523254395,\n",
       " 0.005454063415527344,\n",
       " 0.02174854278564453,\n",
       " 0.01410210132598877,\n",
       " 0.01410210132598877,\n",
       " 0.01365053653717041,\n",
       " 0.01365053653717041,\n",
       " 0.013712882995605469,\n",
       " 0.013712882995605469,\n",
       " 0.00692903995513916,\n",
       " 0.02059948444366455,\n",
       " 0.013747334480285645,\n",
       " 0.013747334480285645,\n",
       " 0.008947372436523438,\n",
       " 0.01857137680053711,\n",
       " 0.004043102264404297,\n",
       " 0.022904634475708008,\n",
       " 0.013510823249816895,\n",
       " 0.013510823249816895,\n",
       " 0.008464813232421875,\n",
       " 0.019429922103881836,\n",
       " 0.008074402809143066,\n",
       " 0.018973946571350098,\n",
       " 0.0074405670166015625,\n",
       " 0.019780874252319336,\n",
       " 0.003938198089599609,\n",
       " 0.02287149429321289,\n",
       " 0.00900280475616455,\n",
       " 0.018549323081970215,\n",
       " 0.013541340827941895,\n",
       " 0.013541340827941895,\n",
       " 0.013573408126831055,\n",
       " 0.013573408126831055,\n",
       " 0.003984570503234863,\n",
       " 0.022926688194274902,\n",
       " 0.004949092864990234,\n",
       " 0.02233290672302246,\n",
       " 0.013551592826843262,\n",
       " 0.013551592826843262,\n",
       " 0.008240222930908203,\n",
       " 0.019063711166381836,\n",
       " 0.004881024360656738,\n",
       " 0.022850632667541504,\n",
       " 0.013696789741516113,\n",
       " 0.013696789741516113,\n",
       " 0.013781547546386719,\n",
       " 0.013781547546386719,\n",
       " 0.008376121520996094,\n",
       " 0.01935601234436035,\n",
       " 0.00406801700592041,\n",
       " 0.023287177085876465,\n",
       " 0.013630270957946777,\n",
       " 0.013630270957946777,\n",
       " 0.006833672523498535,\n",
       " 0.020400643348693848,\n",
       " 0.013609647750854492,\n",
       " 0.013609647750854492,\n",
       " 0.013581156730651855,\n",
       " 0.013581156730651855,\n",
       " 0.005667209625244141,\n",
       " 0.02216029167175293,\n",
       " 0.013524889945983887,\n",
       " 0.013524889945983887,\n",
       " 0.004038810729980469,\n",
       " 0.02286076545715332,\n",
       " 0.005408644676208496,\n",
       " 0.021515488624572754,\n",
       " 0.013671278953552246,\n",
       " 0.013671278953552246,\n",
       " 0.006104230880737305,\n",
       " 0.02109670639038086,\n",
       " 0.0067681074142456055,\n",
       " 0.020275235176086426,\n",
       " 0.01344919204711914,\n",
       " 0.01344919204711914,\n",
       " 0.014072775840759277,\n",
       " 0.014072775840759277,\n",
       " 0.013561367988586426,\n",
       " 0.013561367988586426,\n",
       " 0.008162140846252441,\n",
       " 0.01901113986968994,\n",
       " 0.005494236946105957,\n",
       " 0.021914124488830566,\n",
       " 0.005684614181518555,\n",
       " 0.021767377853393555,\n",
       " 0.0039560794830322266,\n",
       " 0.022889375686645508,\n",
       " 0.009529829025268555,\n",
       " 0.01744556427001953,\n",
       " 0.006851911544799805,\n",
       " 0.020943164825439453,\n",
       " 0.008774995803833008,\n",
       " 0.018207550048828125,\n",
       " 0.009418964385986328,\n",
       " 0.01740431785583496,\n",
       " 0.008783102035522461,\n",
       " 0.018323183059692383,\n",
       " 0.008863210678100586,\n",
       " 0.018583297729492188,\n",
       " 0.008149385452270508,\n",
       " 0.019117355346679688,\n",
       " 0.005456805229187012,\n",
       " 0.021544337272644043,\n",
       " 0.006094574928283691,\n",
       " 0.02083885669708252,\n",
       " 0.006681561470031738,\n",
       " 0.02033984661102295,\n",
       " 0.013364434242248535,\n",
       " 0.013364434242248535,\n",
       " 0.0053751468658447266,\n",
       " 0.02157306671142578,\n",
       " 0.006015419960021973,\n",
       " 0.020813822746276855,\n",
       " 0.008802175521850586,\n",
       " 0.0185244083404541,\n",
       " 0.013581156730651855,\n",
       " 0.013581156730651855,\n",
       " 0.013664841651916504,\n",
       " 0.013664841651916504,\n",
       " 0.008171916007995605,\n",
       " 0.01913750171661377,\n",
       " 0.004754781723022461,\n",
       " 0.023192644119262695,\n",
       " 0.006791353225708008,\n",
       " 0.02034783363342285,\n",
       " 0.006036281585693359,\n",
       " 0.020982742309570312,\n",
       " 0.004001498222351074,\n",
       " 0.02270805835723877,\n",
       " 0.003899097442626953,\n",
       " 0.022765159606933594,\n",
       " 0.004669547080993652,\n",
       " 0.022164463996887207,\n",
       " 0.0133439302444458,\n",
       " 0.0133439302444458,\n",
       " 0.006789207458496094,\n",
       " 0.02002573013305664,\n",
       " 0.007448077201843262,\n",
       " 0.019780755043029785,\n",
       " 0.013640165328979492,\n",
       " 0.013640165328979492,\n",
       " 0.013629317283630371,\n",
       " 0.013629317283630371,\n",
       " 0.00612032413482666,\n",
       " 0.020970463752746582,\n",
       " 0.004755735397338867,\n",
       " 0.022569894790649414,\n",
       " 0.005400657653808594,\n",
       " 0.021526575088500977,\n",
       " 0.0046885013580322266,\n",
       " 0.022361040115356445,\n",
       " 0.004732251167297363,\n",
       " 0.02218759059906006,\n",
       " 0.013584256172180176,\n",
       " 0.013584256172180176,\n",
       " 0.013934969902038574,\n",
       " 0.013934969902038574,\n",
       " 0.013510584831237793,\n",
       " 0.013510584831237793,\n",
       " 0.008939385414123535,\n",
       " 0.01841413974761963,\n",
       " 0.008225560188293457,\n",
       " 0.019653677940368652,\n",
       " 0.013611197471618652,\n",
       " 0.013611197471618652,\n",
       " 0.00878763198852539,\n",
       " 0.018452882766723633,\n",
       " 0.008211612701416016,\n",
       " 0.019098281860351562,\n",
       " 0.013565540313720703,\n",
       " 0.013565540313720703,\n",
       " 0.013814806938171387,\n",
       " 0.013814806938171387,\n",
       " 0.00553441047668457,\n",
       " 0.02189779281616211,\n",
       " 0.013472437858581543,\n",
       " 0.013472437858581543,\n",
       " 0.006787896156311035,\n",
       " 0.020642876625061035,\n",
       " 0.004723310470581055,\n",
       " 0.02220773696899414,\n",
       " 0.006096363067626953,\n",
       " 0.02077174186706543,\n",
       " 0.006735563278198242,\n",
       " 0.02026057243347168,\n",
       " 0.006100773811340332,\n",
       " 0.021371960639953613,\n",
       " 0.013444185256958008,\n",
       " 0.013444185256958008,\n",
       " 0.0134507417678833,\n",
       " 0.0134507417678833,\n",
       " 0.007481575012207031,\n",
       " 0.01965498924255371,\n",
       " 0.009410619735717773,\n",
       " 0.017987728118896484,\n",
       " 0.013708949089050293,\n",
       " 0.013708949089050293,\n",
       " 0.006153702735900879,\n",
       " 0.02111971378326416,\n",
       " 0.007575273513793945,\n",
       " 0.019803524017333984,\n",
       " 0.013436317443847656,\n",
       " 0.013436317443847656,\n",
       " 0.013730406761169434,\n",
       " 0.013730406761169434,\n",
       " 0.013666749000549316,\n",
       " 0.013666749000549316,\n",
       " 0.008088827133178711,\n",
       " 0.01904773712158203,\n",
       " 0.0075452327728271484,\n",
       " 0.020325422286987305,\n",
       " 0.0040819644927978516,\n",
       " 0.02301621437072754,\n",
       " 0.013419747352600098,\n",
       " 0.013419747352600098,\n",
       " 0.013498425483703613,\n",
       " 0.013498425483703613,\n",
       " 0.0046776533126831055,\n",
       " 0.022751450538635254,\n",
       " 0.004011988639831543,\n",
       " 0.022672295570373535,\n",
       " 0.0046607255935668945,\n",
       " 0.02208077907562256,\n",
       " 0.006051898002624512,\n",
       " 0.020619988441467285,\n",
       " 0.01345372200012207,\n",
       " 0.01345372200012207,\n",
       " 0.005520224571228027,\n",
       " 0.021544575691223145,\n",
       " 0.013223886489868164,\n",
       " 0.013223886489868164,\n",
       " 0.008729934692382812,\n",
       " 0.018163204193115234,\n",
       " 0.009540677070617676,\n",
       " 0.018048882484436035,\n",
       " 0.005558609962463379,\n",
       " 0.021848559379577637,\n",
       " 0.00476527214050293,\n",
       " 0.022106647491455078,\n",
       " 0.013398170471191406,\n",
       " 0.013398170471191406,\n",
       " 0.01362597942352295,\n",
       " 0.01362597942352295,\n",
       " 0.004182696342468262,\n",
       " 0.023306965827941895,\n",
       " 0.00875699520111084,\n",
       " 0.01817905902862549,\n",
       " 0.01352536678314209,\n",
       " 0.01352536678314209,\n",
       " 0.013423442840576172,\n",
       " 0.013423442840576172,\n",
       " 0.007783770561218262,\n",
       " 0.019940972328186035,\n",
       " 0.00400543212890625,\n",
       " 0.022797346115112305,\n",
       " 0.003995060920715332,\n",
       " 0.022621750831604004,\n",
       " 0.01341700553894043,\n",
       " 0.01341700553894043,\n",
       " 0.013798832893371582,\n",
       " 0.013798832893371582,\n",
       " 0.004840970039367676,\n",
       " 0.022823691368103027,\n",
       " 0.005421757698059082,\n",
       " 0.02145564556121826,\n",
       " 0.005380988121032715,\n",
       " 0.021535754203796387,\n",
       " 0.0069980621337890625,\n",
       " 0.02044844627380371,\n",
       " 0.007473945617675781,\n",
       " 0.019464731216430664,\n",
       " 0.003969788551330566,\n",
       " 0.022690415382385254,\n",
       " 0.008890151977539062,\n",
       " 0.018348217010498047,\n",
       " 0.004145383834838867,\n",
       " 0.023210763931274414,\n",
       " 0.0054122209548950195,\n",
       " 0.02149808406829834,\n",
       " 0.013430953025817871,\n",
       " 0.013430953025817871,\n",
       " 0.008048057556152344,\n",
       " 0.018671274185180664,\n",
       " 0.0042302608489990234,\n",
       " 0.023366212844848633,\n",
       " 0.005396246910095215,\n",
       " 0.02143275737762451,\n",
       " 0.006674647331237793,\n",
       " 0.020280003547668457,\n",
       " 0.013491153717041016,\n",
       " 0.013491153717041016,\n",
       " 0.004335880279541016,\n",
       " 0.023296117782592773,\n",
       " 0.007967472076416016,\n",
       " 0.01885199546813965,\n",
       " 0.004744172096252441,\n",
       " 0.022040963172912598,\n",
       " 0.013402819633483887,\n",
       " 0.013402819633483887,\n",
       " 0.004934906959533691,\n",
       " 0.022376418113708496,\n",
       " 0.007390022277832031,\n",
       " 0.01963639259338379,\n",
       " 0.003997445106506348,\n",
       " 0.022922873497009277,\n",
       " 0.013549566268920898,\n",
       " 0.013549566268920898,\n",
       " 0.005578279495239258,\n",
       " 0.021875381469726562,\n",
       " 0.008680105209350586,\n",
       " 0.018135547637939453,\n",
       " 0.006081700325012207,\n",
       " 0.02060520648956299,\n",
       " 0.01345062255859375,\n",
       " 0.01345062255859375,\n",
       " 0.013630509376525879,\n",
       " 0.013630509376525879,\n",
       " 0.013381361961364746,\n",
       " 0.013381361961364746,\n",
       " 0.008214235305786133,\n",
       " 0.01928114891052246,\n",
       " 0.008877396583557129,\n",
       " 0.018491387367248535,\n",
       " 0.013897895812988281,\n",
       " 0.013897895812988281,\n",
       " 0.006840944290161133,\n",
       " 0.020397663116455078,\n",
       " 0.005352973937988281,\n",
       " 0.021643877029418945,\n",
       " 0.013523340225219727,\n",
       " 0.013523340225219727,\n",
       " 0.009243249893188477,\n",
       " 0.018957138061523438,\n",
       " 0.004721283912658691,\n",
       " 0.022153019905090332,\n",
       " 0.006738066673278809,\n",
       " 0.02027571201324463,\n",
       " 0.008147001266479492,\n",
       " 0.018808841705322266,\n",
       " 0.005031943321228027,\n",
       " 0.022554516792297363,\n",
       " 0.003958702087402344,\n",
       " 0.022977590560913086,\n",
       " 0.003996729850769043,\n",
       " 0.022765278816223145,\n",
       " 0.007451653480529785,\n",
       " 0.019779324531555176,\n",
       " 0.0060721635818481445,\n",
       " 0.020657896995544434,\n",
       " 0.013434529304504395,\n",
       " 0.013434529304504395,\n",
       " 0.004724025726318359,\n",
       " 0.022345781326293945,\n",
       " 0.013393878936767578,\n",
       " 0.013393878936767578,\n",
       " 0.013692021369934082,\n",
       " 0.013692021369934082,\n",
       " 0.005425930023193359,\n",
       " 0.021620988845825195,\n",
       " 0.013622760772705078,\n",
       " 0.013622760772705078,\n",
       " 0.005481839179992676,\n",
       " 0.021613240242004395,\n",
       " 0.01470959186553955,\n",
       " 0.01470959186553955,\n",
       " 0.013372182846069336,\n",
       " 0.013372182846069336,\n",
       " 0.009472131729125977,\n",
       " 0.017518043518066406,\n",
       " 0.013568878173828125,\n",
       " 0.013568878173828125,\n",
       " 0.008661270141601562,\n",
       " 0.019756793975830078,\n",
       " 0.009543776512145996,\n",
       " 0.017688393592834473,\n",
       " 0.0040929317474365234,\n",
       " 0.023246288299560547,\n",
       " 0.004676222801208496,\n",
       " 0.02225959300994873,\n",
       " 0.013698339462280273,\n",
       " 0.013698339462280273,\n",
       " 0.008782505989074707,\n",
       " 0.018320202827453613,\n",
       " 0.01337575912475586,\n",
       " 0.01337575912475586,\n",
       " 0.009570002555847168,\n",
       " 0.01800668239593506,\n",
       " 0.008935689926147461,\n",
       " 0.018571853637695312,\n",
       " 0.013498067855834961,\n",
       " 0.013498067855834961,\n",
       " 0.004086971282958984,\n",
       " 0.023018360137939453,\n",
       " 0.004014849662780762,\n",
       " 0.02326810359954834,\n",
       " 0.013526082038879395,\n",
       " 0.013526082038879395,\n",
       " 0.004026293754577637,\n",
       " 0.023067831993103027,\n",
       " 0.0053157806396484375,\n",
       " 0.021500587463378906,\n",
       " 0.0133742094039917,\n",
       " 0.0133742094039917,\n",
       " 0.013783931732177734,\n",
       " 0.013783931732177734,\n",
       " 0.008831024169921875,\n",
       " 0.018196821212768555,\n",
       " 0.004701495170593262,\n",
       " 0.02247607707977295,\n",
       " 0.013603925704956055,\n",
       " 0.013603925704956055,\n",
       " 0.008447885513305664,\n",
       " 0.019306659698486328,\n",
       " 0.004881739616394043,\n",
       " 0.022590994834899902,\n",
       " 0.009509921073913574,\n",
       " 0.017674565315246582,\n",
       " 0.013467073440551758,\n",
       " 0.013467073440551758,\n",
       " 0.007650613784790039,\n",
       " 0.01991748809814453,\n",
       " 0.005435824394226074,\n",
       " 0.021669507026672363,\n",
       " 0.006749153137207031,\n",
       " 0.020274877548217773,\n",
       " 0.013295412063598633,\n",
       " 0.013295412063598633,\n",
       " 0.013643980026245117,\n",
       " 0.013643980026245117,\n",
       " 0.004742026329040527,\n",
       " 0.022331833839416504,\n",
       " 0.005323648452758789,\n",
       " 0.021341323852539062,\n",
       " 0.007416129112243652,\n",
       " 0.020076632499694824,\n",
       " 0.013597846031188965,\n",
       " 0.013597846031188965,\n",
       " 0.007511615753173828,\n",
       " 0.019555091857910156,\n",
       " 0.007469892501831055,\n",
       " 0.01964259147644043,\n",
       " 0.013557195663452148,\n",
       " 0.013557195663452148,\n",
       " 0.00824117660522461,\n",
       " 0.019122838973999023,\n",
       " 0.006861329078674316,\n",
       " 0.020374178886413574,\n",
       " 0.0066874027252197266,\n",
       " 0.020032405853271484,\n",
       " 0.00608980655670166,\n",
       " 0.023000121116638184,\n",
       " 0.005468249320983887,\n",
       " 0.021770358085632324,\n",
       " 0.005411386489868164,\n",
       " 0.02167820930480957,\n",
       " 0.008056282997131348,\n",
       " 0.01858198642730713,\n",
       " 0.01342916488647461,\n",
       " 0.01342916488647461,\n",
       " 0.01367199420928955,\n",
       " 0.01367199420928955,\n",
       " 0.008198261260986328,\n",
       " 0.019034147262573242,\n",
       " 0.0067588090896606445,\n",
       " 0.020252585411071777,\n",
       " 0.013440370559692383,\n",
       " 0.013440370559692383,\n",
       " 0.013787269592285156,\n",
       " 0.013787269592285156,\n",
       " 0.008248686790466309,\n",
       " 0.019040942192077637,\n",
       " 0.00884401798248291,\n",
       " 0.01844918727874756,\n",
       " 0.0076264142990112305,\n",
       " 0.020181775093078613,\n",
       " 0.004787921905517578,\n",
       " 0.02246689796447754,\n",
       " 0.013428688049316406,\n",
       " 0.013428688049316406,\n",
       " 0.004098653793334961,\n",
       " 0.023117542266845703,\n",
       " 0.005367875099182129,\n",
       " 0.021810412406921387,\n",
       " 0.013393163681030273,\n",
       " 0.013393163681030273,\n",
       " 0.013541817665100098,\n",
       " 0.013541817665100098,\n",
       " 0.008334517478942871,\n",
       " 0.019049525260925293,\n",
       " 0.004673004150390625,\n",
       " 0.022778987884521484,\n",
       " 0.01356649398803711,\n",
       " 0.01356649398803711]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runner.evaluation_agent_seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runner.states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 8])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.stack([2, 10 - 2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = MultiactorEnvironment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'int', 'num_values': 11}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([5, 5]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
